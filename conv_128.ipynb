{"cells":[{"cell_type":"code","execution_count":null,"id":"78d22595-32bc-4e8c-ae48-9315bdc4165f","metadata":{"id":"78d22595-32bc-4e8c-ae48-9315bdc4165f"},"outputs":[],"source":["from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n","from keras.models import Sequential, Model\n","from keras.layers.advanced_activations import LeakyReLU\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","import tensorflow.keras.activations as activations\n","import tensorflow as tf\n","\n","from keras.preprocessing import image\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import numpy as np\n","\n","from google.colab import drive\n","import os\n","\n","import time"]},{"cell_type":"code","source":["drive.mount('/gdrive', force_remount=True)"],"metadata":{"id":"bOqEj_jklWFL"},"id":"bOqEj_jklWFL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /gdrive/My\\ Drive/IU_MSDS/2021Fall_E533_DL/DLS\\ Final\\ Project\\ /CUB_200_Numpy/\n","os.listdir()"],"metadata":{"id":"8IKIhphxta18"},"execution_count":null,"outputs":[],"id":"8IKIhphxta18"},{"cell_type":"code","execution_count":null,"id":"96bc0500-ef81-4697-b59b-1f0e4b335da6","metadata":{"id":"96bc0500-ef81-4697-b59b-1f0e4b335da6"},"outputs":[],"source":["desired_image_shape = (128, 128)\n","X_train = np.load('CUB200_img_128_c.npy')\n","X_train = X_train.astype('float32') / 255.0\n","np.random.shuffle(X_train)\n","print(f'\\n{X_train.shape[0]} Images of the size {X_train.shape[1]}x{X_train.shape[2]} with {X_train.shape[3]} channels.')"]},{"cell_type":"code","execution_count":null,"id":"ea823047-d5f1-4532-88a7-afc079b2b200","metadata":{"id":"ea823047-d5f1-4532-88a7-afc079b2b200"},"outputs":[],"source":["plt.figure(1, figsize=(10, 10))\n","for i in range(25):\n","    plt.subplot(5, 5, i+1)\n","    plt.imshow(X_train[i])\n","    plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"129e7860-1bcb-4c9c-a073-274487832ce7","metadata":{"id":"129e7860-1bcb-4c9c-a073-274487832ce7"},"outputs":[],"source":["class GAN():\n","    def __init__(self):\n","        \n","        self.img_rows, self.img_cols, self.channels, self.latent_dim = X_train.shape[1], X_train.shape[2], X_train.shape[3], 100\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        optimizer1 = RMSprop(learning_rate=0.0008, clipvalue=1.0, decay=1e-8)\n","        optimizer2 = RMSprop(learning_rate=0.0001, clipvalue=1.0, decay=1e-8)\n","        \n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer1, metrics=['accuracy'])\n","        \n","        self.generator = self.build_generator()\n","\n","        z = Input(shape=(self.latent_dim,))\n","        img = self.generator(z)\n","        validity = self.discriminator(img)\n","        self.combined = Model(z, validity)\n","\n","        self.discriminator.trainable = False\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer2, metrics=['accuracy'])\n","        \n","        \n","    def build_generator(self):\n","\n","        model = Sequential()\n","        model.add(Input(shape=(self.latent_dim,)))\n","\n","        model.add(Dense(128*64*64, use_bias=False))\n","        model.add(LeakyReLU(trainable=False))\n","        model.add(Reshape((64,64,128)))\n","\n","        model.add(Conv2D(256, 5, padding='same', use_bias=False))\n","        model.add(LeakyReLU())\n","\n","        model.add(Conv2DTranspose(256, 4, strides=2, padding='same', use_bias=False))\n","        model.add(LeakyReLU())\n","\n","        model.add(Conv2D(256, 5, padding='same', use_bias=False))\n","        model.add(LeakyReLU())\n","\n","        model.add(Conv2D(256, 5, padding='same', use_bias=False))\n","        model.add(LeakyReLU())\n","\n","        model.add(Conv2D(3, 7, activation='tanh', padding='same', use_bias=False))\n","        \n","        return model\n","    \n","    \n","    def build_discriminator(self):\n","\n","        model=Sequential()\n","        model.add(Input(shape=self.img_shape))\n","\n","        model.add(Conv2D(128, 3, 1))\n","        model.add(LeakyReLU())\n","\n","        model.add(Conv2D(128, 3, 2))\n","        model.add(LeakyReLU())\n","\n","        model.add(Conv2D(128, 3, 2))\n","        model.add(LeakyReLU())\n","\n","        model.add(Conv2D(128, 3, 2))\n","        model.add(LeakyReLU())\n","\n","        model.add(Flatten())\n","        model.add(Dropout(0.3))\n","        model.add(Dense(1, activation='sigmoid'))\n","        \n","        return model\n","    \n","    \n","    def train(self, X_train, epochs=30, batch_size=64, sample_interval=5):\n","                \n","        real_labels = np.ones((batch_size, 1))\n","        fake_labels = np.zeros((batch_size, 1))\n","\n","        d_loss = []\n","        g_loss = []\n","\n","        for epoch in range(epochs):\n","\n","            tic = time.time()\n","            \n","            d_loss_epoch = []\n","            g_loss_epoch = []\n","            \n","            for ite in range(0, X_train.shape[0], batch_size):\n","                \n","                real_images = X_train[ite:ite+batch_size]\n","                \n","                noise1 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","                fake_images = self.generator.predict(noise1)\n","                \n","                all_images = np.vstack([real_images, fake_images])\n","                all_labels = np.vstack([real_labels, fake_labels])\n","                \n","                \n","                shuffler = np.random.permutation(all_images.shape[0])\n","                \n","                all_images = all_images[shuffler]\n","                all_labels = all_labels[shuffler]\n","\n","                d_loss_epoch.append(self.discriminator.train_on_batch(all_images, all_labels)[0])\n","                \n","                noise2 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","                \n","                g_loss_epoch.append(self.combined.train_on_batch(noise2, real_labels)[0])\n","\n","                \n","            g_loss.append(sum(g_loss_epoch)/len(g_loss_epoch))\n","            d_loss.append(sum(d_loss_epoch)/len(d_loss_epoch))\n","\n","            toc = time.time()\n","            \n","            if epoch % sample_interval == 0:\n","                \n","                print(f'Epoch {epoch} - D loss: {d_loss[-1]:.5f}, G_loss: {g_loss[-1]:.5f}, Epoch Time: {round((toc - tic) / 60.0, 3)} minutes')\n","                self.sample_images(epoch)\n","\n","            print()\n","                \n","        return d_loss, g_loss\n","        \n","    def sample_images(self, epoch):\n","        r, c = 3, 3\n","\n","        fig, axs = plt.subplots(r, c, figsize=(6, 6))\n","        for i in range(r):\n","            for j in range(c):\n","                noise = np.random.normal(0, 1, (1, self.latent_dim))\n","                gen_img = self.generator.predict(noise)[0]\n","                gen_img = image.array_to_img(gen_img*255., scale=False)\n","                axs[i,j].imshow(gen_img)\n","                axs[i,j].axis('off')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"c0db4705-cbec-44c7-a139-c339f961353d","metadata":{"id":"c0db4705-cbec-44c7-a139-c339f961353d"},"outputs":[],"source":["g = GAN()"]},{"cell_type":"code","execution_count":null,"id":"8423a6c2-1dcd-4199-87d1-0e527d398360","metadata":{"id":"8423a6c2-1dcd-4199-87d1-0e527d398360"},"outputs":[],"source":["d_loss, g_loss = g.train(X_train, 200, 32, 1)"]},{"cell_type":"code","source":["%cd /gdrive/My\\ Drive/IU_MSDS/2021Fall_E533_DL/DLS\\ Final\\ Project\\ /Project_Notebooks/Project_Models/"],"metadata":{"id":"ZiTczHBt6KSt"},"id":"ZiTczHBt6KSt","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ea0227ba-f0a1-4895-a7ac-f24fce46086f","metadata":{"id":"ea0227ba-f0a1-4895-a7ac-f24fce46086f"},"outputs":[],"source":["g.generator.save_weights('generator_conv_128.h5')\n","g.discriminator.save_weights('discriminator_conv_128.h5')\n","g.combined.save_weights('combined_conv_128.h5')"]},{"cell_type":"code","execution_count":null,"id":"e605ceb6-4261-4469-805e-469e63a6e2a3","metadata":{"id":"e605ceb6-4261-4469-805e-469e63a6e2a3"},"outputs":[],"source":["g_test = GAN()\n","gen = g_test.generator\n","gen.load_weights('generator_conv_128.h5')\n","\n","r, c = 3, 3\n","\n","fig, axs = plt.subplots(r, c, figsize=(6, 6))\n","for i in range(r):\n","    for j in range(c):\n","        noise = np.random.normal(0, 1, (1, 100))\n","        gen_img = gen.predict(noise)[0]\n","        gen_img = image.array_to_img(gen_img*255., scale=False)\n","        axs[i,j].imshow(gen_img)\n","        axs[i,j].axis('off')\n","plt.show()\n","\n","\n","noise = np.random.normal(0, 1, (1, 100))\n","gen_img = gen.predict(noise)[0]\n","gen_img = image.array_to_img(gen_img*255., scale=False)\n","plt.imshow(gen_img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"2154ebb6-a60f-4e55-9bbc-808a6d0fe4c4","metadata":{"id":"2154ebb6-a60f-4e55-9bbc-808a6d0fe4c4"},"outputs":[],"source":[""]}],"metadata":{"environment":{"kernel":"python3","name":"tf2-gpu.2-6.m86","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m86"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"colab":{"name":"conv_128.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}