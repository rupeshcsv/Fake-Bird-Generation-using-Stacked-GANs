{"cells":[{"cell_type":"code","execution_count":null,"id":"78d22595-32bc-4e8c-ae48-9315bdc4165f","metadata":{"id":"78d22595-32bc-4e8c-ae48-9315bdc4165f"},"outputs":[],"source":["from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n","from keras.models import Sequential, Model\n","from keras.layers.advanced_activations import LeakyReLU\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","import tensorflow.keras.activations as activations\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from google.colab import drive\n","import os\n","\n","import numpy as np"]},{"cell_type":"code","source":["drive.mount('/gdrive', force_remount=True)"],"metadata":{"id":"bOqEj_jklWFL"},"execution_count":null,"outputs":[],"id":"bOqEj_jklWFL"},{"cell_type":"code","source":["%cd /gdrive/My\\ Drive/IU_MSDS/2021Fall_E533_DL/DLS\\ Final\\ Project\\ /CUB_200_Numpy/\n","os.listdir()"],"metadata":{"id":"8IKIhphxta18"},"execution_count":null,"outputs":[],"id":"8IKIhphxta18"},{"cell_type":"code","execution_count":null,"id":"96bc0500-ef81-4697-b59b-1f0e4b335da6","metadata":{"id":"96bc0500-ef81-4697-b59b-1f0e4b335da6"},"outputs":[],"source":["desired_image_shape = (64, 64)\n","np_save_file_name = 'CUB_200_' + str(desired_image_shape[0]) + '_by_' + str(desired_image_shape[1]) + '.npy'\n","X_train = np.load(np_save_file_name)\n","X_train = X_train.astype('float32')\n","X_train = X_train[:-12]\n","np.random.shuffle(X_train)\n","print(f'\\n{X_train.shape[0]} Images of the size {X_train.shape[1]}x{X_train.shape[2]} with {X_train.shape[3]} channels.')"]},{"cell_type":"code","execution_count":null,"id":"ea823047-d5f1-4532-88a7-afc079b2b200","metadata":{"id":"ea823047-d5f1-4532-88a7-afc079b2b200"},"outputs":[],"source":["plt.figure(1, figsize=(10, 10))\n","for i in range(25):\n","    plt.subplot(5, 5, i+1)\n","    plt.imshow(X_train[i] * 0.5 + 0.5)\n","    plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"129e7860-1bcb-4c9c-a073-274487832ce7","metadata":{"id":"129e7860-1bcb-4c9c-a073-274487832ce7"},"outputs":[],"source":["class GAN():\n","    def __init__(self):\n","        \n","        self.img_rows, self.img_cols, self.channels, self.latent_dim = X_train.shape[1], X_train.shape[2], X_train.shape[3], 100\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        optimizer1 = Adam(learning_rate=0.00015, beta_1=0.5)\n","        optimizer2 = Adam(learning_rate=0.00015, beta_1=0.5)\n","        \n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer1, metrics=['accuracy'])\n","        \n","        self.generator = self.build_generator()\n","\n","        z = Input(shape=(self.latent_dim,))\n","        img = self.generator(z)\n","        validity = self.discriminator(img)\n","        self.combined = Model(z, validity)\n","\n","        self.discriminator.trainable = False\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer2, metrics=['accuracy'])\n","        \n","        \n","    def build_generator(self):\n","\n","        model = Sequential()\n","        model.add(Input(shape=(self.latent_dim,)))\n","        model.add(Dense(256))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(1024))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(self.img_rows * self.img_cols * self.channels, activation='tanh'))\n","        model.add(Reshape(self.img_shape))\n","        \n","        return model\n","    \n","    \n","    def build_discriminator(self):\n","\n","        model=Sequential()\n","        model.add(Input(shape=self.img_shape))\n","        model.add(Flatten())\n","        model.add(Dense(256))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(64))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.3))\n","        model.add(Dense(1, activation='sigmoid'))\n","        \n","        return model\n","    \n","    \n","    def train(self, X_train, epochs=30, batch_size=64, sample_interval=5):\n","                \n","        real_labels = np.ones((batch_size, 1))\n","        fake_labels = np.zeros((batch_size, 1))\n","\n","        d_loss = []\n","        g_loss = []\n","\n","        for epoch in range(epochs):\n","            \n","            d_loss_epoch = []\n","            g_loss_epoch = []\n","            \n","            for ite in range(0, X_train.shape[0], batch_size):\n","                \n","                real_images = X_train[ite:ite+batch_size]\n","                \n","                noise1 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","                fake_images = self.generator.predict(noise1)\n","                \n","                all_images = np.vstack([real_images, fake_images])\n","                all_labels = np.vstack([real_labels, fake_labels])\n","                \n","                \n","                shuffler = np.random.permutation(all_images.shape[0])\n","                \n","                all_images = all_images[shuffler]\n","                all_labels = all_labels[shuffler]\n","\n","                d_loss_epoch.append(self.discriminator.train_on_batch(all_images, all_labels)[0])\n","                \n","                noise2 = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","                \n","                g_loss_epoch.append(self.combined.train_on_batch(noise2, real_labels)[0])\n","\n","                \n","            g_loss.append(sum(g_loss_epoch)/len(g_loss_epoch))\n","            d_loss.append(sum(d_loss_epoch)/len(d_loss_epoch))\n","            \n","            if epoch % sample_interval == 0:\n","                \n","                print(f'Epoch {epoch} - D loss: {d_loss[-1]:.5f}, G_loss: {g_loss[-1]:.5f}')\n","                self.sample_images(epoch)\n","                \n","        return d_loss, g_loss\n","        \n","    def sample_images(self, epoch):\n","        r, c = 3, 3\n","\n","        fig, axs = plt.subplots(r, c, figsize=(6, 6))\n","        for i in range(r):\n","            for j in range(c):\n","                noise = np.random.normal(0, 1, (1, self.latent_dim))\n","                gen_img = self.generator.predict(noise)[0]\n","                axs[i,j].imshow(gen_img * 0.5 + 0.5)\n","                axs[i,j].axis('off')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"c0db4705-cbec-44c7-a139-c339f961353d","metadata":{"id":"c0db4705-cbec-44c7-a139-c339f961353d"},"outputs":[],"source":["g = GAN()"]},{"cell_type":"code","execution_count":null,"id":"8423a6c2-1dcd-4199-87d1-0e527d398360","metadata":{"id":"8423a6c2-1dcd-4199-87d1-0e527d398360"},"outputs":[],"source":["d_loss, g_loss = g.train(X_train, 200, 32, 1)"]},{"cell_type":"code","source":["%cd /gdrive/My\\ Drive/IU_MSDS/2021Fall_E533_DL/DLS\\ Final\\ Project\\ /Project_Notebooks/Project_Models/"],"metadata":{"id":"ZiTczHBt6KSt"},"execution_count":null,"outputs":[],"id":"ZiTczHBt6KSt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CXoVIgyky4m"},"outputs":[],"source":["g.generator.save_weights('generator_dense_64.h5')\n","g.discriminator.save_weights('discriminator_dense_64.h5')\n","g.combined.save_weights('combined_dense_64.h5')"],"id":"-CXoVIgyky4m"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HVV7AxGky4m"},"outputs":[],"source":["g_test = GAN()\n","gen = g_test.generator\n","gen.load_weights('generator_dense_64.h5')\n","\n","r, c = 3, 3\n","\n","fig, axs = plt.subplots(r, c, figsize=(6, 6))\n","for i in range(r):\n","    for j in range(c):\n","        noise = np.random.normal(0, 1, (1, 100))\n","        gen_img = gen.predict(noise)[0]\n","        axs[i,j].imshow(gen_img * 0.5 + 0.5)\n","        axs[i,j].axis('off')\n","plt.show()\n","\n","\n","noise = np.random.normal(0, 1, (1, 100))\n","gen_img =  gen.predict(noise)[0] * 0.5 + 0.5\n","plt.imshow(gen_img)\n","plt.show()"],"id":"8HVV7AxGky4m"},{"cell_type":"code","execution_count":null,"metadata":{"id":"orOg_Wa9ky4n"},"outputs":[],"source":[""],"id":"orOg_Wa9ky4n"}],"metadata":{"environment":{"kernel":"python3","name":"tf2-gpu.2-6.m86","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m86"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"colab":{"name":"dense_64.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}